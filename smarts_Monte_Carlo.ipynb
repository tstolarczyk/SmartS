{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Sparse Method Algorithm for Research of Transcients Signal\n",
    "\n",
    "Find transient source in data cubes\n",
    "\n",
    "F. Acero, T. Stolarczyk, A. Chalumeau, Juin 2018\n",
    "\n",
    "This notebook will:\n",
    "\n",
    "    - Generate the fake data cubes (X,Y,T) (signal, background, total) for the Monte Carlo method\n",
    "    - Filter the noise in the cubes using wavelet\n",
    "    - Write the simulated datas on the disk\n",
    "    - Measure how well the methods performed\n",
    "\n",
    "All the code is pure Python (with the exception of one of the denoising method, which requires the binary file msvst_2d1d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import scipy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import PowerNorm\n",
    "import matplotlib.gridspec as gridspec\n",
    "#from matplotlib.colors import Normalize\n",
    "\n",
    "from gammapy.stats import significance\n",
    "from gammapy.stats import significance_on_off\n",
    "\n",
    "from astropy.convolution import convolve,convolve_fft,Gaussian1DKernel,Gaussian2DKernel,Tophat2DKernel\n",
    "from astropy.visualization import simple_norm\n",
    "from astropy.io import fits\n",
    "from astropy.wcs import WCS\n",
    "from astropy.coordinates import SkyCoord,Angle\n",
    "from astropy.wcs import WCS\n",
    "import astropy.units as u\n",
    "from astropy.table import Table\n",
    "\n",
    "from scipy.stats import norm\n",
    "from scipy import interpolate\n",
    "from scipy.ndimage import zoom\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from ipywidgets import interact, fixed\n",
    "import os,subprocess,sys,getpass,copy\n",
    "import time as systime\n",
    "import multiprocessing as mp\n",
    "from functools import partial\n",
    "from collections import defaultdict\n",
    "\n",
    "#import line_profiler\n",
    "#%load_ext line_profiler\n",
    "#from scipy.stats import chisqprob\n",
    "#from scipy.special import erfinv,erf,erfcx\n",
    "\n",
    "import smartcube as smart\n",
    "import scipy.integrate as sc\n",
    "import pywi\n",
    "from pywi.processing.transform import starlet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defining variables for user vheyraud\n",
      "Directories :\n",
      "    - Root              : ./\n",
      "    - MSVST_2d1d binary : \n",
      "    - Input             : ./\n",
      "    - Output            : ./bin/Monte_Carlo/\n",
      "    - Scores            : ./\n",
      "    - Figures           : ./\n"
     ]
    }
   ],
   "source": [
    "#### Global variables and initialisations\n",
    "# Path to the binary file - This is lame and adding the binary file to somewhere accesible by $PATH shoud be enough.\n",
    "#prog='/Users/facero/Documents/Work/CTA/CTA-AIM/code/image-cleaning/msvst/build/msvst_2d1d'\n",
    "\n",
    "user = getpass.getuser()\n",
    "print(\"Defining variables for user\",user)\n",
    "exit\n",
    "if (user==\"achalume\"):\n",
    "    root_dir   = \"/Users/achalume/Documents/Stage/Codes/\" \n",
    "    bin_dir    = \"/Users/achalume/Documents/Lib_files/Sparse2D/build/\"\n",
    "elif (user==\"stolar\"):\n",
    "    root_dir   = \"/home/stolar/Code/\" \n",
    "    bin_dir    = root_dir + \"bin/\"\n",
    "elif (user==\"vheyraud\"):\n",
    "    root_dir = (\"./\")\n",
    "    bin_dir    = \"\"\n",
    "\n",
    "#input_dir  = root_dir + \"GRB-Fermi/FAWT3D/FermiData/\"\n",
    "#output_dir = root_dir + \"GRB-Fermi/FAWT3D/output/\"\n",
    "#msvst      = bin_dir  + \"msvst_2d1d\"\n",
    "#score_dir  = root_dir + \"GRB-Fermi/FAWT3D/scores/\"\n",
    "#fig_dir    = root_dir + \"GRB-Fermi/FAWT3D/Figures/\"\n",
    "\n",
    "input_dir  = root_dir\n",
    "output_dir = \"./bin/Monte_Carlo/\"\n",
    "msvst      = \"msvst_2d1d\"\n",
    "score_dir  = root_dir\n",
    "fig_dir    = root_dir\n",
    "wave2D     = \"./wl_t2_filter \"\n",
    "acceptance_file = \"Acceptance-LST-ctapipe.txt\"\n",
    "\n",
    "\n",
    "#### Check existences\n",
    "if not os.path.exists(output_dir) :\n",
    "    os.makedirs(output_dir)\n",
    "if not os.path.exists(fig_dir) :\n",
    "    os.makedirs(fig_dir)\n",
    "if not os.path.exists(score_dir) :\n",
    "    os.makedirs(score_dir)\n",
    "    \n",
    "print(\"Directories :\")\n",
    "print(\"    - Root              :\",root_dir)\n",
    "print(\"    - MSVST_2d1d binary :\",bin_dir)\n",
    "print(\"    - Input             :\",input_dir)\n",
    "print(\"    - Output            :\",output_dir)\n",
    "print(\"    - Scores            :\",score_dir)\n",
    "print(\"    - Figures           :\",fig_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# LC function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def LCBinChange(pre_t,pre_LC,fact_T_bin):\n",
    "    \"\"\"\n",
    "    Re-bin a light curve multiplying the initial bin size with fact_T_bin. Returns : new_t,new_LC\n",
    "    \"\"\"\n",
    "    \n",
    "    alpha = fact_T_bin\n",
    "\n",
    "    new_t = np.zeros(int(len(pre_t)/alpha)) ; new_LC = np.zeros(len(new_t))\n",
    "    for i in range(0,len(new_t)):\n",
    "        new_t[i] = pre_t[int(i*alpha)]\n",
    "        new_LC[i] = np.sum(pre_LC[int((alpha*i)):int((alpha*i)+alpha)])\n",
    "\n",
    "    return new_t,new_LC\n",
    "\n",
    "############################################\n",
    "def NormLC(LC,value,time,tmin,tmax):\n",
    "    \"\"\"\n",
    "    Norm a range in a light curve (SUM(LC) = value from tmin to tmax). Returns : Normed_LC\n",
    "    \"\"\"\n",
    "    LC_range = LC[np.where((time>=tmin) & (time<=tmax))]\n",
    "    Normed_LC = value*LC/(np.sum(LC_range))\n",
    "    \n",
    "    return Normed_LC\n",
    "                    \n",
    "############################################\n",
    "def InterpFunction(x_val,y_val,x_val_new):\n",
    "    \"\"\"\n",
    "    Interpolate y(x) to get an approached function (y_new) with a given xtable (x_val_new). Returns : y_new\n",
    "    \"\"\"\n",
    "    \n",
    "    f = interpolate.interp1d(x_val,y_val)\n",
    "    y_new = f(x_val_new)\n",
    "    \n",
    "    return y_new\n",
    "\n",
    "############################################\n",
    "def MakeLCTh(timebin,Xi,Tmintot,Tmaxtot,Ntotrange,Tminrange,Tmaxrange):\n",
    "    \"\"\"\n",
    "    Make the theoretical LC normalizing at Ntotrange from Tminrange to Tmaxrange. Returns : Time, LC\n",
    "    \"\"\"\n",
    "    \n",
    "    T_0 = Tmintot\n",
    "    Time = np.arange(Tmintot,Tmaxtot+timebin,timebin)\n",
    "    K = (Tminrange**Xi)*(1+Xi)*Ntotrange/(Tmaxrange**(1+Xi) - Tminrange**(1+Xi))\n",
    "    LC = K*Tminrange**(-Xi)*((Time)**(Xi+1)-(Time-timebin)**(Xi+1))/(Xi+1)\n",
    "    \n",
    "    return Time,LC\n",
    "############################################\n",
    "def MakeLCFa(datafile,Timebin,Bin_Factor,Ntotrange,Tminrange,Tmaxrange):\n",
    "    \"\"\"\n",
    "    From Fabio's file, make LC normalizing at Ntotrange from Tminrange to Tmaxrange\\\n",
    "    choosing an initial bin size (Timebin). Returns : Time,LC\n",
    "    \"\"\"\n",
    "    \n",
    "    TimeData,LCData = np.loadtxt(datafile,unpack=True)\n",
    "    Time = TimeData - TimeData[0] ; Time_size = TimeData[-1] - TimeData[0]   \n",
    "    \n",
    "    # Decrease time bin using an interpolation\n",
    "    TimeInterp  = [x*Timebin for x in range(0,int(Time_size/Timebin),1)]\n",
    "    TimeInterp = np.array(TimeInterp)\n",
    "    LC = InterpFunction(Time,LCData,TimeInterp)\n",
    "    \n",
    "    LC_norm = NormLC(LC,Ntotrange,TimeInterp,Tminrange,Tmaxrange)\n",
    "    T_input,LC_input = LCBinChange(TimeInterp,LC_norm,Bin_Factor) \n",
    "    \n",
    "    return T_input,LC_input\n",
    "\n",
    "############################################\n",
    "def MakeLCIn(datafile,Timebin,Bin_Factor,Ntotrange,Tminrange,Tmaxrange):\n",
    "    \"\"\"\n",
    "    From Inoue's extrapolated LC, make LC normalizing at Ntotrange from Tminrange to Tmaxrange.\\\n",
    "    Initial time bin (0.5) taken from the article. Returns : Time, LC\n",
    "    \"\"\"\n",
    "    \n",
    "    TData,LCData = np.genfromtxt(datafile,unpack=True,skip_header=6)\n",
    "\n",
    "    # Set time values\n",
    "    TData_0 = round(TData[0]) ; TData_end = np.round(TData[-1]/Timebin)*(Timebin)\n",
    "    Time = np.linspace(TData_0,TData_end,len(TData))\n",
    "    # Set LC values\n",
    "    LC = LCData * Timebin # Put light curve in counts (it was in Cts/Bin before)\n",
    "    LC = np.rint(LC).astype(int) # Set counts values\n",
    "\n",
    "    T_input,LC_input = LCBinChange(Time,LC,Bin_Factor)\n",
    "    LC_norm = NormLC(LC_input,Ntotrange,T_input,Tminrange,Tmaxrange)\n",
    "\n",
    "    return T_input,LC_norm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Cube fonctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def BkgCube(time,SteadSrcPeak,bkg):\n",
    "    \"\"\"\n",
    "    Creates the background model cube from a background value and a steady source peak.\\\n",
    "    Returns : BkgCube\n",
    "    \"\"\"\n",
    "    BkgToycube = smart.CreateBkgModelCube(time,sigmaX,sigmaY,SteadSrcPeak,bkg,n2Dsize,pixelsize,Acceptance)\n",
    "    BkgCube = smart.NoiseCube(BkgToycube)\n",
    "    \n",
    "    return BkgCube\n",
    "\n",
    "############################################\n",
    "def ImageCube(LC,time,SrcPeak,xcent,ycent,SteadSrcPeak,bkg):\n",
    "    \"\"\"\n",
    "    Creates a cube containing bkg + transcient source. Returns : Fluctuated Signal+Bkg, Fluctuated Signal,Fluctuated Bkg\n",
    "    \"\"\"\n",
    "    \n",
    "    BkgToycube = smart.CreateBkgModelCube(time,sigmaX,sigmaY,SteadSrcPeak,bkg,n2Dsize,pixelsize,Acceptance)    \n",
    "    \n",
    "    #Create cubes' lists\n",
    "    SrcCube = smart.CreateSignalModelCube(LC,SrcPeak,xcent,ycent,sigmaX,sigmaY,n2Dsize,pixelsize,Acceptance)\n",
    "    SignalNoisyCube = smart.NoiseCube(SrcCube)\n",
    "    BkgNoisyCube = smart.NoiseCube(BkgToycube)\n",
    "    NoisyCube = SignalNoisyCube+BkgNoisyCube\n",
    "    \n",
    "    return (NoisyCube,SignalNoisyCube,BkgNoisyCube)\n",
    "\n",
    "############################################\n",
    "def BkgModelCube(time,tmin,tmax,tbin,SteadSrcPeak,bkg):\n",
    "    \"\"\"\n",
    "    Create a bkg model cube (size = time) containing at each timebin the same image corresponding\\\n",
    "    to a perfectly known background. Returns : BkgModelCube\n",
    "    \n",
    "    Note : this function can be largely simplified, some parameters are useless (tmin,tmax,tbin..)\n",
    "    \"\"\"\n",
    "        \n",
    "    TimeAccum = np.arange(tmin,tmax+1,tbin)\n",
    "\n",
    "    BkgToycube = smart.CreateBkgModelCube(TimeAccum,sigmaX,sigmaY,SteadSrcPeak,bkg,n2Dsize,pixelsize,Acceptance)\n",
    "    \n",
    "    #BkgNoisyCube = smart.NoiseCube(BkgToycube)\n",
    "    BkgMeanImage = smart.CumulCube(BkgToycube)[:,:,-1]/(len(TimeAccum))\n",
    "    \n",
    "    BkgModelCube = np.zeros((len(BkgToycube[:,0,0]),len(BkgToycube[0,:,0]),len(time)))\n",
    "    for t in range(0,len(time)):\n",
    "        BkgModelCube[:,:,t] = BkgMeanImage\n",
    "    \n",
    "    return BkgModelCube\n",
    "\n",
    "############################################\n",
    "def BkgAcCube(tmin,tmax,tbin,SteadSrcPeak,bkg):\n",
    "    \"\"\"\n",
    "    Create a bkg acquisition cube containing at each time bin the same image corresponding to\n",
    "    and accumulated bkg from tmin to tmax(with tbins). Returns : BkgAcCue\n",
    "    \"\"\"\n",
    "    TimeAccum = np.arange(tmin,tmax+1,tbin)\n",
    "    \n",
    "    BkgToycube = smart.CreateBkgModelCube(TimeAccum,sigmaX,sigmaY,SteadSrcPeak,bkg,n2Dsize,pixelsize,Acceptance)\n",
    "    BkgNoisyCube = smart.NoiseCube(BkgToycube)\n",
    "\n",
    "    return BkgNoisyCube\n",
    "\n",
    "############################################\n",
    "def WavCleaning(cube_noisy_file,wc_file,command):\n",
    "    \"\"\"\n",
    "    Cube cleaning using wavelet transforms with msvst_2d1d (a shift is made to fix some argues,\\\n",
    "    maybe it should be seen better). Returns : Cube cleaned\n",
    "    \"\"\"\n",
    "    \n",
    "    cmd='%s  %s %s %s'%(msvst,command,cube_noisy_file,wc_file)\n",
    "    subprocess.call(cmd,shell=True) # USE msvst_2d1d FILE\n",
    "\n",
    "    #### Read wavelets cleaned cube file\n",
    "    cube_wc,header_wc = smart.ReadCubeFromFile(wc_file,'fits')\n",
    "    \n",
    "    #### Cube shifting to fix msvst_2d1d's shift \n",
    "    cube_wc_shift = copy.deepcopy(cube_wc)\n",
    "    cube_wc_shift[...,:-1] = cube_wc[...,1:] # Shift (time) to (time-1) (to see if its from msvst_2d1d)\n",
    "    \n",
    "    return cube_wc_shift\n",
    "\n",
    "################################################\n",
    "def WavCleaning2D(cube_noisy_file,wc_file,command):\n",
    "    \"\"\"\n",
    "    Cube cleaning using wavelet transforms with mr_filter.\n",
    "    Returns : Cube cleaned\n",
    "    \"\"\"\n",
    "    \n",
    "    cmd='%s  %s %s %s '%(wave2D,command,cube_noisy_file,wc_file)\n",
    "    subprocess.call(cmd,shell=True)\n",
    "\n",
    "    #### Read wavelets cleaned cube file\n",
    "    cube_wc,header_wc = smart.ReadCubeFromFile(wc_file,'fits')\n",
    "    \n",
    "    return cube_wc\n",
    "#################################################\n",
    "def CreateAcceptance(flg,file):\n",
    "    \"flg = 0 : gaussian acceptance with width sigma_vig, flg = 1 interpolated acceptance from file\"\n",
    "    data = Table.read(filename=file,format=\"ascii\")\n",
    "    theta2 = data[\"theta2\"]\n",
    "    counts = data[\"counts\"]\n",
    "    Empirical = interpolate.interp1d(x=theta2,y=counts)\n",
    "    x = np.linspace(0, n2Dsize-1, n2Dsize)\n",
    "    y = np.linspace(0, n2Dsize-1, n2Dsize)\n",
    "    x,y = np.meshgrid(x, y)\n",
    "    Acceptance=np.empty((n2Dsize,n2Dsize))\n",
    "    xo,yo=n2Dsize//2,n2Dsize//2\n",
    "    \n",
    "    if flg==0:\n",
    "        Acceptance=np.exp( - ((x-xo)**2+(y-yo)**2)/(2*(sigma_vignetting/pixelsize)**2))\n",
    "    if flg==1:\n",
    "        theta2=((x-xo)**2+(y-yo)**2)*pixelsize**2\n",
    "        theta2[xo,yo]=1# Necessary to avoid an error related to the interpolation error when theta2=0\n",
    "        Acceptance=Empirical(theta2)\n",
    "        Acceptance[xo,yo]=1# correct the value at the center\n",
    "        #Acceptance=Empirical(((x-xo)**2+(y-yo)**2)*pixelsize**2+0.0002) : to use this we must add a small value cause the interpolation isn't defined in 0\n",
    "    return Acceptance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# My Main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Instrument response function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instrument response function\n",
      "----------------------------\n",
      "  Field of view       :  4.5\n",
      "  Pixel size          :  0.1\n",
      "  N. of pixels        :  45 x 45\n",
      "  Mean CTA background :  0.04  (cts/s/pix, 50<E<500 GeV)\n"
     ]
    }
   ],
   "source": [
    "FOV               = 4.5    #width in degrees\n",
    "pixelsize         = 0.1   #in degrees\n",
    "n2Dsize           = int(FOV/pixelsize)\n",
    "sigma_vignetting  = 1.8    # (deg) from ctobssim\n",
    "ct95 = 0.2\n",
    "a = 0.95\n",
    "sigma_PSF         = smart.sigma_from_containment_radius(ct95,a)   # (deg) Since the psf isn't a gaussian, we use half of the 95% containement radius and the shape of a gaussian\n",
    "background        = 0.04    # cts/s/pixel in E=50-500 GeV at center of FoV. Tbin=10s bkg=0.1\n",
    "sigmaX, sigmaY   = float(sigma_PSF/pixelsize),  float(sigma_PSF/pixelsize) # Point like source\n",
    "Acceptance=CreateAcceptance(0,acceptance_file)\n",
    "\n",
    "print(\"Instrument response function\")\n",
    "print(\"----------------------------\")\n",
    "print(\"  Field of view       : \",FOV)\n",
    "print(\"  Pixel size          : \",pixelsize)\n",
    "print(\"  N. of pixels        : \",n2Dsize,\"x\",n2Dsize)\n",
    "print(\"  Mean CTA background : \",background,\" (cts/s/pix, 50<E<500 GeV)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Make LC and cubes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 54  58  62  66  70  74  78  82  86  90  94  98 102 106 110 114 118 122\n",
      " 126 130 134 138 142 146 150 154 158 162 166 170 174]\n"
     ]
    }
   ],
   "source": [
    "##################################\n",
    "# Create 3 LC choosing normalisation range (t_min_norm,t_max_norm) and value (Ntot_norm)\n",
    "# Each LC and time correspond to a name.\n",
    "# Timebin[name] = Tbin_input[name]\n",
    "# Time,LC_Values = T_input[name],LC_input[name]\n",
    "##################################\n",
    "\n",
    "LC_input,T_input,t_min_norm,t_max_norm = {},{},{},{} ; Tbin_input = {}\n",
    "\n",
    "#### Make theoretical LC\n",
    "Th_name = 'Theoretical'\n",
    "Tbin_input[Th_name] = 4 # se\n",
    "xi   = -1.4\n",
    "t_min_Th = 30 ; t_0_Th = t_min_Th\n",
    "t_max_Th = 200\n",
    "Ntot_norm_Th = 1115 # From Inoue \n",
    "t_min_norm_Th = 50\n",
    "t_max_norm_Th = 94\n",
    "T_input[Th_name],LC_input[Th_name] =\\\n",
    "    MakeLCTh(Tbin_input[Th_name],xi,t_min_Th,t_max_Th,Ntot_norm_Th,t_min_norm_Th,t_max_norm_Th)\n",
    "\n",
    "#### Make LC from Fabio\n",
    "Fa_name = 'Fabio LC'\n",
    "TBin_Fa = 1\n",
    "Bin_Factor_Fa = 6\n",
    "Tbin_input[Fa_name] = TBin_Fa*Bin_Factor_Fa\n",
    "Ntot_norm_Fa = 200\n",
    "t_min_norm_Fa = 90\n",
    "t_max_norm_Fa = 110\n",
    "data_file_Fabio = input_dir+\"LAT-GRB130427.dat\"\n",
    "T_input[Fa_name],LC_input[Fa_name] =\\\n",
    "   MakeLCFa(data_file_Fabio,TBin_Fa,Bin_Factor_Fa,Ntot_norm_Fa,t_min_norm_Fa,t_max_norm_Fa)\n",
    "\n",
    "#### Make LC from Inoue\n",
    "In_name = 'Inoue LC'\n",
    "TBin_data_In = 0.5\n",
    "Bin_Factor_In = 8\n",
    "Tbin_input[In_name] = TBin_data_In*Bin_Factor_In\n",
    "Ntot_norm_In = 1115\n",
    "t_min_norm_In = 50\n",
    "t_max_norm_In = 94\n",
    "data_file_Inoue = input_dir+\"Inoue_LC_080916C.dat\"\n",
    "T_input[In_name],LC_input[In_name] =\\\n",
    "    MakeLCIn(data_file_Inoue,TBin_data_In,Bin_Factor_In,Ntot_norm_In,t_min_norm_In,t_max_norm_In)\n",
    "\n",
    "##################################\n",
    "# Choose main parameters : Source position and values (list), steady source value, which LC from the 3.\n",
    "# Then select the differents timeranges from tnew_min until Tnew_max (array)\n",
    "# Get a dict containing a LC with different sizes\n",
    "##################################\n",
    "\n",
    "xcenter, ycenter = 22,22#25,25#10,10# Position Center of GRB on Image (px,px)\n",
    "Relative_effective_area_correction=1#0.73 #1#0.9 for a 1.4° offset, 0.73 for a 2.47° offset \n",
    "SteadySourcePeak = 0. # Quiescent source - intensity\n",
    "\n",
    "name = Th_name # Th_name ; Fa_name ; In_name\n",
    "TimeInput = T_input[name]\n",
    "LCInput = LC_input[name]*Relative_effective_area_correction\n",
    "Bkg_input = Tbin_input[name]*background\n",
    "\n",
    "Tnew_min = 24 \n",
    "Tmax=174\n",
    "\n",
    "T_new,LC_new = {},{}\n",
    "T_new = TimeInput[np.where((TimeInput>=(TimeInput[0]+Tnew_min)) & (TimeInput<=Tmax))]\n",
    "LC_new = LCInput[np.where((TimeInput>=(TimeInput[0]+Tnew_min)) & (TimeInput<=Tmax))]\n",
    "print(T_new)\n",
    "\n",
    "#print('tmin = %ss, tmax values (s) = %s\\nTimebin = %s s'%(np.min(T_new[tmax]),Tnew_max,Tbin_input[name]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Performances : Monte-Carlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 75, 80, 85, 90, 95, 100, inf]\n"
     ]
    }
   ],
   "source": [
    "## Set source intensity list\n",
    "\n",
    "RedFactorList = [1,5,10,15,20,25,30,35,40,45,50,55,60,65,70,75,80,85,90,95,100,np.inf]#\n",
    "\n",
    "print(RedFactorList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 27min 59s, sys: 2min 36s, total: 30min 36s\n",
      "Wall time: 30min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## Monte-Carlo simulation\n",
    "\n",
    "Niterate = 400\n",
    "Tmax=T_new[-1]\n",
    "wav = 2 # choose the wavelet filtering method : 1 : 2D1D, 2 : 2D PyWI, 3 : 1+2, 4 : 2D Sparse2D\n",
    "\n",
    "# Known background methods\n",
    "TminBkg, TmaxBkg,TbinBkg = 0,60,Tbin_input[name]\n",
    "\n",
    "# Wavelets 2D1D method\n",
    "cmd2D1D = '-N4 -f3 -n4 -F2 -s5 -T'\n",
    "\n",
    "#cmd = '-f2 -F2 -s2  -T'\n",
    "#Wavelets 2D method\n",
    "cmd2D = '-n4 -m2 -P -s3 -k -K -C1 -F2 -v'\n",
    "\n",
    "# Wavelets 2DPywi method\n",
    "threshold_list=[100,0]#\n",
    "\n",
    "\n",
    "for i in range(0,Niterate):\n",
    "    \n",
    "    ## Create the fluctuated background model and the acquired background\n",
    "    \n",
    "    BkgModel = BkgModelCube(T_new,TminBkg,TmaxBkg,TbinBkg,SteadySourcePeak,Bkg_input)\n",
    "    BkgAc = BkgAcCube(TminBkg,TmaxBkg,TbinBkg,SteadySourcePeak,Bkg_input)\n",
    "        \n",
    "    smart.WriteCubeToFile(BkgAc,output_dir+'AcBkgCube_%i_%i.fits'%(TmaxBkg-TminBkg,i),'')\n",
    "    smart.WriteCubeToFile(BkgModel,output_dir+'ModelBkg_%i_%i.fits'%(Tmax,i),'')\n",
    "\n",
    "for RedFactor in RedFactorList:\n",
    "    \n",
    "    for i in range(0,Niterate):\n",
    "\n",
    "\n",
    "        ## Create the simulated signal, background and signal+background, the model background and accumulated background cubes\n",
    "        \n",
    "        CubeList = ImageCube(LC_new,T_new,1/RedFactor,xcenter,ycenter,SteadySourcePeak,Bkg_input)\n",
    "        Total = CubeList[0]\n",
    "        Signal = CubeList[1]\n",
    "        Bkg = CubeList[2]\n",
    "        \n",
    "        WaveFilt = np.zeros(np.shape(Total))\n",
    "        \n",
    "        ## Write the created cubes in specific directories in the bin\n",
    "\n",
    "        smart.WriteCubeToFile(Signal,output_dir+'FlucSignal_%s_%i.fits'%(RedFactor,i),'')\n",
    "        smart.WriteCubeToFile(Total,output_dir+'FlucTotal_%s_%i.fits'%(RedFactor,i),'')\n",
    "        smart.WriteCubeToFile(Bkg,output_dir+'FlucBkg_%s_%i.fits'%(RedFactor,i),'')\n",
    "\n",
    "        \n",
    "        # WAVELETS\n",
    "        \n",
    "        if wav==1 or wav==3 :\n",
    "            \n",
    "            for t in T_new:\n",
    "            \n",
    "                Cubefile = output_dir+'FlucTotal_%s_%i_%i.fits'%(RedFactor,i,t)\n",
    "                WCubefile = output_dir+'WavCube2D1D_%s_%i_%i.fits'%(RedFactor,i,t)\n",
    "                \n",
    "                k=np.int(np.where(T_new==t)[0])\n",
    "\n",
    "                Cube_temp = Total[:,:,:k+1]\n",
    "                smart.WriteCubeToFile(Cube_temp,Cubefile,'')\n",
    "                \n",
    "                WavCleaning(Cubefile,WCubefile,cmd2D1D) \n",
    "                \n",
    "        if wav==2 or wav==3 :\n",
    "            \n",
    "            Total=smart.ReadCubeFromFile(output_dir+'FlucTotal_%s_%i.fits'%(RedFactor,i),\"fits\")[0]#to be removed\n",
    "            \n",
    "            for k in range(len(T_new)):\n",
    "                \n",
    "                img=smart.CumulCube(Total)[:,:,k]\n",
    "                WaveFilt[:,:,k]=pywi.processing.compositing.filter_with_starlet.clean_image(img,type_of_filtering='ksigma_hard_filtering',\\\n",
    "                            filter_thresholds=threshold_list,last_scale_treatment='mask',detect_only_positive_structures=True)\n",
    "                smart.WriteCubeToFile(WaveFilt,output_dir+'WavCube2D_%s_%i.fits'%(RedFactor,i),'')\n",
    "        \n",
    "        if wav==4 :\n",
    "            \n",
    "            for t in T_new:\n",
    "                \n",
    "                Cubefile = output_dir+'FlucTotal_%s_%i_%i.fits'%(RedFactor,i,t)\n",
    "                WCubefile = output_dir+'WavCube_%s_%i_%i.fits'%(RedFactor,i,t)\n",
    "                \n",
    "                k=np.int(np.where(T_new==t)[0])\n",
    "\n",
    "                Cube_temp = Total[:,:,:k+1]\n",
    "                smart.WriteCubeToFile(np.nansum(Cube_temp,axis=2),Cubefile,'')\n",
    "                \n",
    "                temp=WavCleaning2D(Cubefile,WCubefile,cmd2D) \n",
    "            \n",
    "        print(i+1,'done in',Niterate,end='\\r')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Attachments",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
